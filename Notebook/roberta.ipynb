{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting seed and checking GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Set random seed and set device to GPU.\n",
    "torch.manual_seed(17)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "# Initialize tokenizer.\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "df['length'] = df['review'].apply(lambda x: len(x.split()))\n",
    "sns.distplot(df[df['length'] < 5000]['length'])\n",
    "plt.title('Frequence of documents of a given length', fontsize=14)\n",
    "plt.xlabel('length', fontsize=14)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tokenizer hyperparameters.\n",
    "MAX_SEQ_LEN = 256\n",
    "PRE_TRAINING_TRAIN_BATCH_SIZE = 32\n",
    "PRE_TRAINING_VAL_BATCH_SIZE = 64\n",
    "PRE_TRAINING_TEST_BATCH_SIZE = 64\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
    "PRE_TRAINING_DATASET_PATH = \"./new.csv\"\n",
    "\n",
    "# Define columns to read.\n",
    "review_field = Field(use_vocab=False, \n",
    "                   tokenize=tokenizer.encode, \n",
    "                   include_lengths=False, \n",
    "                   batch_first=True,\n",
    "                   fix_length=MAX_SEQ_LEN, \n",
    "                   pad_token=PAD_INDEX, \n",
    "                   unk_token=UNK_INDEX)\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True)\n",
    "\n",
    "fields = {'review' : ('review', review_field), 'label' : ('label', label_field)}\n",
    "\n",
    "\n",
    "# Read preprocessed CSV into TabularDataset and split it into train, test and valid.\n",
    "train, valid, test = TabularDataset(path=PRE_TRAINING_DATASET_PATH, \n",
    "                                                   format='CSV', \n",
    "                                                   fields=fields, \n",
    "                                                   skip_header=False).split(split_ratio=[0.80, 0.1, 0.1], \n",
    "                                                                            stratified=True, \n",
    "                                                                            strata_field='label')\n",
    "\n",
    "training_set_iter = Iterator(valid, batch_size=PRE_TRAINING_TRAIN_BATCH_SIZE, device=device, train=True, shuffle=True, sort=True)\n",
    "valid_set_iter = Iterator(valid, batch_size=PRE_TRAINING_VAL_BATCH_SIZE, device=device, train=False, shuffle=False, sort=True)\n",
    "# Test iterator, no shuffling or sorting required.\n",
    "test_set_iter = Iterator(test, batch_size=PRE_TRAINING_TEST_BATCH_SIZE, device=device, train=False, shuffle=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(path, train_loss_list, valid_loss_list, global_steps_list):   \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    torch.save(state_dict, path)\n",
    "\n",
    "\n",
    "def load_metrics(path):    \n",
    "    state_dict = torch.load(path, map_location=device)\n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with extra layers on top of RoBERTa\n",
    "class ROBERTA(torch.nn.Module):\n",
    "    def __init__(self, dropout_rate=0.3):\n",
    "        super(ROBERTA, self).__init__()\n",
    "        \n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.d1 = torch.nn.Dropout(dropout_rate)\n",
    "        self.l1 = torch.nn.Linear(768, 256)\n",
    "        self.bn1 = torch.nn.LayerNorm(256)\n",
    "        self.l2 = torch.nn.Linear(256, 64)\n",
    "        self.bn2 = torch.nn.LayerNorm(64)\n",
    "        self.d2 = torch.nn.Dropout(dropout_rate)\n",
    "        self.l3 = torch.nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, x = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = self.d1(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = torch.nn.Tanh()(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.l3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain(model, optimizer, training_set_iter, valid_set_iter, scheduler, num_epochs):\n",
    "    \n",
    "    # Pretrain linear layers, do not train bert\n",
    "    for param in model.roberta.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # Initialize losses and loss histories\n",
    "      \n",
    "    global_step = 0  \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Train loop\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0 \n",
    "        for (review, label), _ in train_iter:\n",
    "            mask = (review != PAD_INDEX).type(torch.uint8)\n",
    "            \n",
    "            y_pred = model(input_ids=source, attention_mask=mask)\n",
    "            \n",
    "            loss = criterion(y_pred, label)\n",
    "   \n",
    "            loss.backward()\n",
    "            \n",
    "            # Optimizer and scheduler step\n",
    "            optimizer.step()    \n",
    "            scheduler.step()\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Update train loss and global step\n",
    "            train_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # Validation loop. Save progress and evaluate model performance.\n",
    "            if global_step % valid_period == 0:\n",
    "                \n",
    "                model.eval()\n",
    "                \n",
    "                with torch.no_grad():                    \n",
    "                    for (review, target), _ in valid_iter:\n",
    "                        mask = (review != PAD_INDEX).type(torch.uint8)\n",
    "                        \n",
    "                        y_pred = model(input_ids=review, attention_mask=mask)\n",
    "                        \n",
    "                        loss = criterion(y_pred, label)\n",
    "                        \n",
    "                        valid_loss += loss.item()\n",
    "\n",
    "                # Store train and validation loss history\n",
    "                train_loss = train_loss / len(training_set_iter)\n",
    "                valid_loss = valid_loss / len(valid_set_iter)\n",
    "                \n",
    "                model.train()\n",
    "\n",
    "                # print summary\n",
    "                print('Epoch [{}/{}], Pre-Training Loss: {:.4f}, Val Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, train_loss, valid_loss))\n",
    "    \n",
    "    # Set bert parameters back to trainable\n",
    "    for param in model.roberta.parameters():\n",
    "        param.requires_grad = True\n",
    "     \n",
    "    # Saving Pre-Trained Model as .pth file\n",
    "    torch.save({'model_state_dict': model.state_dict()}, \"./preTrained_model.pth\")\n",
    "        \n",
    "    print('Pre-training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "PRE_TRAINING_NUM_EPOCHS = 12\n",
    "steps_per_epoch = len(train_iter)\n",
    "\n",
    "PRE_TRAINING_model = ROBERTA(0.4)\n",
    "PRE_TRAINING_model = PRE_TRAINING_model.to(device)\n",
    "\n",
    "\n",
    "PRE_TRAINING_optimizer = AdamW(PRE_TRAINING_model.parameters(), lr=1e-4)\n",
    "PRE_TRAINING_scheduler = get_linear_schedule_with_warmup(PRE_TRAINING_optimizer, \n",
    "                                            num_warmup_steps=steps_per_epoch*1, \n",
    "                                            num_training_steps=steps_per_epoch*PRE_TRAINING_NUM_EPOCHS)\n",
    "\n",
    "pretrain(model=PRE_TRAINING_model, training_set_iter=training_set_iter, valid_set_iter=valid_set_iter, optimizer=PRE_TRAINING_optimizer, scheduler=PRE_TRAINING_scheduler, num_epochs=PRE_TRAINING_NUM_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tokenizer hyperparameters.\n",
    "CLASSIFIER_MAX_SEQ_LEN = 256\n",
    "CLASSIFIER_TRAIN_BATCH_SIZE = 32\n",
    "CLASSIFIER_VAL_BATCH_SIZE = 64\n",
    "CLASSIFIER_TEST_BATCH_SIZE = 64\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
    "CLASSIFIER_DATASET_PATH = \"../dataset/classify/final_prepro1.csv\"\n",
    "\n",
    "# Define columns to read.\n",
    "review_field = Field(use_vocab=False, \n",
    "                   tokenize=tokenizer.encode, \n",
    "                   include_lengths=False, \n",
    "                   batch_first=True,\n",
    "                   fix_length=CLASSIFIER_MAX_SEQ_LEN, \n",
    "                   pad_token=PAD_INDEX, \n",
    "                   unk_token=UNK_INDEX)\n",
    "\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True)\n",
    "\n",
    "fields = {'review' : ('review', review_field), 'label' : ('label', label_field)}\n",
    "\n",
    "\n",
    "# Read preprocessed CSV into TabularDataset and split it into train, test and valid.\n",
    "train, valid, test = TabularDataset(path=CLASSIFIER_DATASET_PATH, \n",
    "                                                   format='CSV', \n",
    "                                                   fields=fields, \n",
    "                                                   skip_header=False).split(split_ratio=[0.70, 0.1, 0.2], \n",
    "                                                                            stratified=True, \n",
    "                                                                            strata_field='label')\n",
    "\n",
    "training_set_iter = Iterator(valid, batch_size=CLASSIFIER_TRAIN_BATCH_SIZE, device=device, train=True, shuffle=True,sort_key=lambda x: len(x.review), sort=True, sort_within_batch=False)\n",
    "valid_set_iter = Iterator(valid, batch_size=CLASSIFIER_VAL_BATCH_SIZE, device=device, train=False,  shuffle=True,sort_key=lambda x: len(x.review), sort=True, sort_within_batch=False)\n",
    "# Test iterator, no shuffling or sorting required.\n",
    "test_set_iter = Iterator(test, batch_size=CLASSIFIER_TEST_BATCH_SIZE, device=device, train=False, shuffle=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6729"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with extra layers on top of RoBERTa\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, input_ch = 768, dropout_rate=0.3):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "#         self.l1 = torch.nn.Linear(input_ch, 256)\n",
    "#         self.bn1 = torch.nn.LayerNorm(256)\n",
    "        self.l2 = torch.nn.Linear(256, 64)\n",
    "        self.bn2 = torch.nn.LayerNorm(64)\n",
    "        self.d2 = torch.nn.Dropout(dropout_rate)\n",
    "        self.l3 = torch.nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "#         x = self.l1(input_ids)\n",
    "#         x = self.bn1(x)\n",
    "        x = self.l2(input_ids)\n",
    "        x = self.bn2(x)\n",
    "        x = torch.nn.Tanh()(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.l3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(model, optimizer, training_set_iter, valid_set_iter, scheduler, num_epochs, preTrain_path):\n",
    "    \n",
    "    \n",
    "#     preTrained_unet = torch.jit.load(preTrain_path)\n",
    "#     model.load_state_dict(preTrained_unet, strict = False)\n",
    "#     Initialize losses and loss histories\n",
    "    state_dict = torch.load('../preTrained_model.pth')\n",
    "    model.load_state_dict(state_dict['model_state_dict'], strict=False)\n",
    "    global_step = 0  \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Train loop\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0 \n",
    "        for (review, label), _ in training_set_iter:\n",
    "            y_pred = model(input_ids=review.float())\n",
    "            \n",
    "            loss = criterion(y_pred, label)\n",
    "   \n",
    "            loss.backward()\n",
    "            \n",
    "            # Optimizer and scheduler step\n",
    "            optimizer.step()    \n",
    "            scheduler.step()\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Update train loss and global step\n",
    "            train_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # Validation loop. Save progress and evaluate model performance.\n",
    "            if global_step % len(training_set_iter) == 0:\n",
    "                \n",
    "                model.eval()\n",
    "                \n",
    "                with torch.no_grad():                    \n",
    "                    for (review, label), _ in valid_set_iter:\n",
    "                        \n",
    "                        y_pred = model(input_ids=review.float())\n",
    "                        \n",
    "                        loss = criterion(y_pred, label)\n",
    "                        \n",
    "                        valid_loss += loss.item()\n",
    "\n",
    "                # Store train and validation loss history\n",
    "                train_loss = train_loss / len(training_set_iter)\n",
    "                valid_loss = valid_loss / len(valid_set_iter)\n",
    "                \n",
    "                model.train()\n",
    "\n",
    "                # print summary\n",
    "                print('Epoch [{}/{}], Pre-Training Loss: {:.4f}, Val Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, train_loss, valid_loss))\n",
    "     \n",
    "    # Saving Pre-Trained Model as .pth file\n",
    "    torch.save({'model_state_dict': model.state_dict()}, \"./final_model2.pth\")\n",
    "        \n",
    "    print('Classification done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 2.00 GiB total capacity; 1.12 GiB already allocated; 110.88 MiB free; 1.20 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-560bf2d3da3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mCLASSIFIER_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mROBERTA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mCLASSIFIER_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCLASSIFIER_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    605\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    374\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 2.00 GiB total capacity; 1.12 GiB already allocated; 110.88 MiB free; 1.20 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# Main training loop\n",
    "CLASSIFIER_NUM_EPOCHS = 12\n",
    "steps_per_epoch = len(training_set_iter)\n",
    "\n",
    "CLASSIFIER_model = ROBERTA()\n",
    "CLASSIFIER_model = CLASSIFIER_model.to(device)\n",
    "\n",
    "\n",
    "CLASSIFIER_optimizer = AdamW(CLASSIFIER_model.parameters(), lr=1e-4)\n",
    "CLASSIFIER_scheduler = get_linear_schedule_with_warmup(CLASSIFIER_optimizer, \n",
    "                                            num_warmup_steps=steps_per_epoch*1, \n",
    "                                            num_training_steps=steps_per_epoch*CLASSIFIER_NUM_EPOCHS)\n",
    "\n",
    "classifier(model=CLASSIFIER_model,optimizer=CLASSIFIER_optimizer, training_set_iter=training_set_iter, valid_set_iter=valid_set_iter,  scheduler=CLASSIFIER_scheduler, num_epochs=CLASSIFIER_NUM_EPOCHS, preTrain_path='./final_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['roberta.embeddings.position_ids', 'roberta.embeddings.word_embeddings.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'l1.weight', 'l1.bias', 'bn1.weight', 'bn1.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ROBERTA()\n",
    "model = model.to(device)\n",
    "state_dict = torch.load('./final_model1.pth', map_location=device)\n",
    "model.load_state_dict(state_dict['model_state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5628    0.8851    0.6881       496\n",
      "           0     0.6851    0.2667    0.3839       465\n",
      "\n",
      "    accuracy                         0.5858       961\n",
      "   macro avg     0.6240    0.5759    0.5360       961\n",
      "weighted avg     0.6220    0.5858    0.5409       961\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate(model, test_set_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (source, target), _ in test_loader:\n",
    "                mask = (source != PAD_INDEX).type(torch.uint8)\n",
    "                \n",
    "                output = model(source, attention_mask=mask)\n",
    "\n",
    "                y_pred.extend(torch.argmax(output, axis=-1).tolist())\n",
    "                y_true.extend(target.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['negative', 'positive'])\n",
    "    ax.yaxis.set_ticklabels(['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ROBERTA()\n",
    "model = model.to(device)\n",
    "state_dict = torch.load('../preTrained_model.pth')\n",
    "model.load_state_dict(state_dict['model_state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 2.00 GiB total capacity; 1.21 GiB already allocated; 14.88 MiB free; 1.30 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-36f2c3d296be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-22b35163079c>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, test_loader)\u001b[0m\n\u001b[0;32m      8\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mPAD_INDEX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-0f7ef011e047>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroberta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\transformers\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         )\n\u001b[0;32m    687\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\transformers\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    422\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m                 )\n\u001b[0;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\transformers\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         )\n\u001b[0;32m    345\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\transformers\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m         )\n\u001b[0;32m    279\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Installed Software\\Anaconda3\\lib\\site-packages\\transformers\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 2.00 GiB total capacity; 1.21 GiB already allocated; 14.88 MiB free; 1.30 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "evaluate(model, test_set_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('../preTrained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'collections.OrderedDict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-24d59fa14604>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_state_dict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-56-cc3f0f130e4e>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, test_loader)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                 \u001b[1;31m#print(source.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'collections.OrderedDict' object is not callable"
     ]
    }
   ],
   "source": [
    "evaluate(state_dict['model_state_dict'], test_set_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
